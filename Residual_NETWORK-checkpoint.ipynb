{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "# import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "# from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RESIDUAL](./1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RESIDUAL](./RESID.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RESIDUAL](./ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RESIDUAL](./idblock2_kiank.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_block(X , f ,filters ,stage ,block):\n",
    "    \n",
    "    \"\"\"\n",
    "    input\n",
    "    X 輸入的大小(維度)\n",
    "    f 中間遮罩大小\n",
    "    filters  list存遮罩數量\n",
    "    stage 區域名稱\n",
    "    block stage 下的 小名稱\n",
    "    \n",
    "    return \n",
    "    X   shape(n_H ,n_W , n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    #定義 name\n",
    "    conv_name=\"res\"+str(stage)+block+\"_branch\"\n",
    "    bn_name=\"bn\"+str(stage)+block+\"_branch\"\n",
    "    \n",
    "    #抓出F1 ,F2 ,F3\n",
    "    F1 ,F2 ,F3=filters\n",
    "    \n",
    "    #記下CNN 的頭\n",
    "    X_shortcut = X\n",
    "    \n",
    "    #CNN 原路\n",
    "    #1\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid',\n",
    "               name = conv_name + '2a',\n",
    "               kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #2\n",
    "    \n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f) , strides=(1,1) ,padding=\"same\" ,\n",
    "               name=conv_name+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3 ,name=bn_name+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #3\n",
    "    \n",
    "    X = Conv2D(filters=F3 , kernel_size=(1,1) ,strides=(1,1) ,padding=\"valid\" ,\n",
    "               name=conv_name+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3 ,name=bn_name+\"2c\")(X)\n",
    "    \n",
    "    #最後 主路線 加上捷徑\n",
    "    \n",
    "    X = Add()([X_shortcut , X])\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "        \n",
    "    X_shortcut = X  #存頭\n",
    "    \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F2 , kernel_size=(f,f) ,strides=(1,1) ,padding=\"same\" , name=conv_name_base+\"2b\",\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3 ,name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Conv2D(F3 ,kernel_size=(1,1) ,strides=(1,1) ,padding=\"valid\" ,name=conv_name_base+\"2c\",\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3 ,name=bn_name_base+\"2c\")(X)\n",
    "    \n",
    "    X_shortcut = Conv2D(filters=F3 ,kernel_size=(1,1),strides=(s,s),padding=\"valid\",\n",
    "                       name=conv_name_base+\"1\",kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3 ,name=bn_name_base+\"1\")(X_shortcut)\n",
    "    \n",
    "    X = Add()([X , X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (28, 28, 1), classes = 10):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = id_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = id_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X,f=3,filters=[128,128,512] ,stage=3,block=\"a\",s=2)\n",
    "    X = id_block(X, f=3, filters=[128,128,512], stage=3, block=\"b\")\n",
    "    X = id_block(X, f=3, filters=[128,128,512], stage=3, block=\"c\")\n",
    "    X = id_block(X, f=3, filters=[128,128,512], stage=3, block=\"d\")\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block=\"a\", s=2)\n",
    "    X = id_block(X, f=3, filters=[256,256,1024], stage=4, block=\"b\")\n",
    "    X = id_block(X, f=3, filters=[256,256,1024], stage=4, block=\"c\")\n",
    "    X = id_block(X, f=3, filters=[256,256,1024], stage=4, block=\"d\")\n",
    "    X = id_block(X, f=3, filters=[256,256,1024], stage=4, block=\"e\")\n",
    "    X = id_block(X, f=3, filters=[256,256,1024], stage=4, block=\"f\")\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f=3, filters=[512,512,2048], stage=5, block=\"a\", s=2)\n",
    "    X = id_block(X, f=3, filters=[512,512,2048], stage=5, block=\"b\")\n",
    "    X = id_block(X, f=3, filters=[512,512,2048], stage=5, block=\"c\")\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2,2),padding=\"same\")(X)\n",
    "\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\David\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = (28, 28, 1), classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\David\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.2550 - acc: 0.9278\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0765 - acc: 0.9773\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0829 - acc: 0.9765\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0633 - acc: 0.9811\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2341 - acc: 0.9473\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0839 - acc: 0.9751\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0511 - acc: 0.9844\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0454 - acc: 0.9867\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0443 - acc: 0.9869\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0364 - acc: 0.9892\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0368 - acc: 0.9892\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1973 - acc: 0.9614\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0957 - acc: 0.9742\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0446 - acc: 0.9867\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0451 - acc: 0.9866\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0563 - acc: 0.9849\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0337 - acc: 0.9898\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0255 - acc: 0.9923\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0248 - acc: 0.9925\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0238 - acc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2716dcca9e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 20, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
